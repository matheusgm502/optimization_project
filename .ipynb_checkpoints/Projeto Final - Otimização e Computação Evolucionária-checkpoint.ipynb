{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Otimização e Computação Evolucionária\n",
    "\n",
    "\n",
    "## Alunos: Eduardo Ximenes, Matheus Gomes Maranhão, Vitor Peter\n",
    "\n",
    "O presente projeto foi realizado como atividade de conclusão da disciplina de Otimização e Computação Evolucionária. A atividade consiste no uso dos conhecimentos adquiridos ao longo das aulas, através da aplicação do Algoritmos Genético e Particle Swarm Optimization com o objetivo de realizar a clusterização de um dataset e regressão com seleção de features no outro dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score, jaccard_score, r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Churn Prediction  \n",
    "Com este dataset, será feita uma clusterização com o modelo KMeans usando um método fit ajustado por computação evolucionária. A ideia será comparar essa solução com o modelo padrão. A métrica utilizada foi o índice de silhueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('./data/churn_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15606229</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15569892</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15584532</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15682355</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15628319</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  credit_score  country  gender  age  tenure    balance  \\\n",
       "0        15634602           619   France  Female   42       2       0.00   \n",
       "1        15647311           608    Spain  Female   41       1   83807.86   \n",
       "2        15619304           502   France  Female   42       8  159660.80   \n",
       "3        15701354           699   France  Female   39       1       0.00   \n",
       "4        15737888           850    Spain  Female   43       2  125510.82   \n",
       "...           ...           ...      ...     ...  ...     ...        ...   \n",
       "9995     15606229           771   France    Male   39       5       0.00   \n",
       "9996     15569892           516   France    Male   35      10   57369.61   \n",
       "9997     15584532           709   France  Female   36       7       0.00   \n",
       "9998     15682355           772  Germany    Male   42       3   75075.31   \n",
       "9999     15628319           792   France  Female   28       4  130142.79   \n",
       "\n",
       "      products_number  credit_card  active_member  estimated_salary  churn  \n",
       "0                   1            1              1         101348.88      1  \n",
       "1                   1            0              1         112542.58      0  \n",
       "2                   3            1              0         113931.57      1  \n",
       "3                   2            0              0          93826.63      0  \n",
       "4                   1            1              1          79084.10      0  \n",
       "...               ...          ...            ...               ...    ...  \n",
       "9995                2            1              0          96270.64      0  \n",
       "9996                1            1              1         101699.77      0  \n",
       "9997                1            0              1          42085.58      1  \n",
       "9998                2            1              0          92888.52      1  \n",
       "9999                1            1              0          38190.78      0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Housing Prices  \n",
    "Com este dataset, será feita uma regressão com o modelo SVR usando features selecionadas por computação evolucionária. A ideia será comparar essa solução com o modelo utilizando todas as features, e com o modelo utilizando features escolhidas pelo PCA. As métricas utilizadas foram R² e MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000  7420         4          2        3      yes        no       no   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_housing = pd.read_csv('./data/housing_price.csv')\n",
    "print(df_housing.head(1))\n",
    "df_housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes' 'no']\n",
      "['no' 'yes']\n",
      "['no' 'yes']\n",
      "['no' 'yes']\n",
      "['yes' 'no']\n",
      "['yes' 'no']\n",
      "['furnished' 'semi-furnished' 'unfurnished']\n"
     ]
    }
   ],
   "source": [
    "print(df_housing.mainroad.unique())\n",
    "print(df_housing.guestroom.unique())\n",
    "print(df_housing.basement.unique())\n",
    "print(df_housing.hotwaterheating.unique())\n",
    "print(df_housing.airconditioning.unique())\n",
    "print(df_housing.prefarea.unique())\n",
    "print(df_housing.furnishingstatus.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the first argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1540\\3102602017.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdict_house\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'no'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yes'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mbooleans_house\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mainroad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'guestroom'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'basement'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hotwaterheating'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'airconditioning'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefarea'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_housing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbooleans_house\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_housing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbooleans_house\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_house\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_housing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[0;32m  10111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10113\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10115\u001b[1;33m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10117\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10118\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: the first argument must be callable"
     ]
    }
   ],
   "source": [
    "dict_house = {'no':0, 'yes':1}\n",
    "booleans_house = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "df_housing[booleans_house] = df_housing[booleans_house].map(dict_house)\n",
    "df_housing.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computação evolucionária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a fitness no GA e no PSO\n",
    "def fitness_function(ind_encoded, beta, X, y):\n",
    "\n",
    "    # ind é um subconjunto de features: [0 0 1 0 0 1 ...]\n",
    "    ind = decode_ind(ind_encoded, beta)\n",
    "    m, n = X.shape\n",
    "    # inicializar o alpha\n",
    "    alpha = np.inf\n",
    "    for i in range(m): # iterate over all samples\n",
    "        for j in range(i + 1, m): # iterate over all samples\n",
    "            if y[i] != y[j]: # if i and j are not from the same class\n",
    "                distance_ij = np.sum([(X[i,k] - X[j,k])**2 * ind[k] for k in range(n)])\n",
    "                alpha = min(alpha, distance_ij)\n",
    "\n",
    "    # Maximizando o mínimo alpha, então deve-se negativar o valor antes\n",
    "    return -alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que gera pop inicial\n",
    "def init_pop(P,X):\n",
    "    \"\"\"\n",
    "    Inicialize um conjunto de indivíduos, cada um contendo elementos entre 0 e 1.\n",
    "\n",
    "    Parâmetros:\n",
    "    X: dados de treinamento\n",
    "    P: número de indivíduos na população\n",
    "\n",
    "    Retorna:\n",
    "    pop: população inicial\n",
    "    \"\"\"\n",
    "    pop = []\n",
    "    m, n = X.shape\n",
    "    for _ in range(P):\n",
    "        ind = [np.random.uniform(0, 1) for __ in range(n)] # chaves aleatórias\n",
    "        pop.append(ind)\n",
    "\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para decodificar o indivíduo\n",
    "def decode_ind(ind, beta):\n",
    "    \"\"\"\n",
    "    Decodificar um indivíduo definindo 'beta' elementos com a maior\n",
    "    probabilidade como 1 e os demais como 0.\n",
    "\n",
    "    Parâmetros:\n",
    "    ind: indivíduo a ser decodificado.\n",
    "    beta: O número de elementos a serem definidos como 1.\n",
    "\n",
    "    Retorna:\n",
    "    ind: indivíduo a ser decodificado.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtenha os índices dos 'beta' maiores elementos\n",
    "    indices_of_highest = sorted(range(len(ind)), key=lambda i: ind[i], reverse=True)[:beta]\n",
    "    # []\n",
    "\n",
    "    # Innicialize o indivíduo decodificado\n",
    "    decoded_ind = [0] * len(ind)\n",
    "\n",
    "    # Inclua um total de 'beta' elementos iguais a 1\n",
    "    for index in indices_of_highest:\n",
    "        decoded_ind[index] = 1\n",
    "\n",
    "    return decoded_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_individuals(population, elite_size): # elitism is used\n",
    "    \"\"\"\n",
    "    Selecionar dois indivíduos aleatoriamente da população P vezes.\n",
    "    Como utilizamos elitismo, devemos reduzir o número de indivídos selecionados\n",
    "\n",
    "    Parâmetros:\n",
    "    population: Lista ou array representando a população.\n",
    "    elite_size: Tamanho da elite\n",
    "\n",
    "    Retorna:\n",
    "    Lista de tuplas, cada uma contendo os índices de dois indivíduos selecionados aleatoriamente.\n",
    "    \"\"\"\n",
    "    population_size = len(population)-math.ceil(elite_size)\n",
    "\n",
    "    selections = []\n",
    "    for _ in range(population_size):\n",
    "        # Selecione dois indivíduos aleatoriamente com reposição\n",
    "        selected_indices = np.random.choice(population_size, size=2, replace=True)\n",
    "        selections.append(tuple(selected_indices))\n",
    "\n",
    "    return selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_crossover(parent1, parent2, crossover_rate=0.5):\n",
    "    \"\"\"\n",
    "    Realizar crossover uniforme entre dois pais.\n",
    "\n",
    "    Parâmetros:\n",
    "\n",
    "    parent1: genes do primeiro pai.\n",
    "    parent2: genes do segundo pai.\n",
    "    crossover_rate: Probabilidade de selecionar um gene do primeiro pai.\n",
    "\n",
    "    Retorna:\n",
    "    genes do filho após o crossover uniforme.\n",
    "    \"\"\"\n",
    "\n",
    "    # Gerar uma lista aleatória booleana, onde o elemento da lista é igual a True, se p < crossover_rate\n",
    "    mask = np.random.rand(len(parent1)) < crossover_rate\n",
    "\n",
    "    # Realizar crossover\n",
    "    child = np.where(mask, parent1, parent2)\n",
    "\n",
    "    return child.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(child, p_m=0.2, mutation_std_dev=0.01):\n",
    "    \"\"\"\n",
    "\n",
    "    Aplicar mutação aos genes de uma criança.\n",
    "\n",
    "    Parâmetros:\n",
    "    child: genes da criança.\n",
    "    p_m: Probabilidade de aplicar mutação a cada gene.\n",
    "    mutation_std_dev: Desvio padrão da distribuição normal para a mutação.\n",
    "\n",
    "    Retorna:\n",
    "    genes da criança após a mutação.\n",
    "\n",
    "    * obs.: o std_dev foi reduzido e 0.1 para 0.01\n",
    "    \"\"\"\n",
    "    mutated_child = np.copy(child)\n",
    "\n",
    "    # Faça o loop em cada gene e mute-o com probabilidade p_m\n",
    "    for i in range(len(child)):\n",
    "        if np.random.rand() < p_m:\n",
    "            # Aplique a mutação perturbando o gene com uma distribuição normal\n",
    "            mutated_child[i] += np.random.normal(loc=0, scale=mutation_std_dev)\n",
    "\n",
    "    return mutated_child.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(pop_size, p_crossover, p_mutation, data, labels, beta, max_generations, elite_size):\n",
    "    \"\"\"\n",
    "    Loop do GA.\n",
    "\n",
    "    Parâmetros:\n",
    "    - pop_size: Population size.\n",
    "    - p_crossover: Crossover probability.\n",
    "    - p_mutation: Mutation probability.\n",
    "    - data: Dataset.\n",
    "    - labels: labels das amostras.\n",
    "    - beta: tamanho do subconjunto de features\n",
    "    - max_generations: Maximum number of generations.\n",
    "    - elite_size: tamanho da elite\n",
    "\n",
    "    Retorna:\n",
    "    - Melhor subconjunto de características obtido pelo GA\n",
    "    \"\"\"\n",
    "    # inicializar os dados\n",
    "    X = data\n",
    "    y = labels\n",
    "    # gerar pop inicial\n",
    "    pop = init_pop(pop_size,X)\n",
    "    # Listas para guardar melhores fitness e indivíduos\n",
    "    fitness_over_time = []\n",
    "    bestind_over_time = []\n",
    "    for generation in range(max_generations):\n",
    "        print(\"G: \" + str(generation))\n",
    "        # Avaliar a fitness de cada indivíduo\n",
    "        #fitness_values = [fitness_function(ind, beta, X, y) for ind in pop]\n",
    "        # Encontrar melhores indivíduos de acordo com a fitness\n",
    "        best_ind = sorted(pop, key=lambda ind: fitness_function(ind, beta, X, y))[:math.ceil(elite_size)]\n",
    "        # Guardar as melhores fitness e indivíduos\n",
    "        best_fitness_val = fitness_function(best_ind[0], beta, X, y)\n",
    "        print(-best_fitness_val)\n",
    "        fitness_over_time.append(-best_fitness_val)\n",
    "        bestind_over_time.append(best_ind[0])\n",
    "        #print(best_ind[0])\n",
    "\n",
    "        # Selecionar pais para reprodução\n",
    "        selections = select_individuals(pop, elite_size)\n",
    "\n",
    "        # Gerar nova pop através de crossover e mutação\n",
    "        offspring = []\n",
    "        for parent1, parent2 in selections:\n",
    "            child = uniform_crossover(pop[parent1], pop[parent2], p_crossover)\n",
    "            child = mutation(child, p_mutation)\n",
    "            offspring.append(child)\n",
    "\n",
    "        # Atualizar população\n",
    "        pop = offspring\n",
    "        pop.extend(best_ind)\n",
    "\n",
    "    return best_ind[0], fitness_over_time, bestind_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que gera enxame inicial\n",
    "def init_swarm(P,X):\n",
    "    \"\"\"\n",
    "    Inicialize um enxame com P partículas, cada uma contendo elementos entre 0 e 1.\n",
    "\n",
    "    Parâmetros:\n",
    "    X: dados de treinamento\n",
    "    P: número de indivíduos no enxame\n",
    "\n",
    "    Retorna:\n",
    "    pos = posição inicial das P partículas do enxame\n",
    "    vel = velocidade inicial das P partículas do enxame\n",
    "    pos_best = vetor de melhores posições conhecidas pela partícula\n",
    "    \"\"\"\n",
    "    pos = []\n",
    "    vel = []\n",
    "    pos_best = []\n",
    "    m, n = X.shape\n",
    "    for _ in range(P):\n",
    "        pos_ind = [np.random.uniform(0, 1) for __ in range(n)] # chaves aleatórias\n",
    "        pos.append(pos_ind)\n",
    "        pos_best.append(pos_ind)\n",
    "        vel.append(np.random.uniform(-1,1, size = n))\n",
    "\n",
    "    return pos, vel, pos_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atualizar velocidade da partícula\n",
    "def update_velocity(pos, vel, pos_best, global_best, w, c1, c2):\n",
    "  '''\n",
    "    Atualiza a velocidade da partícula usando a fórmula da Otimização por Enxame de Partículas (PSO).\n",
    "\n",
    "    Parâmetros:\n",
    "    pos: posição atual da partícula\n",
    "    vel: velocidade atual da partícula\n",
    "    pos_best: Melhor posição global entre todas as partículas.\n",
    "    c1: Parâmetro cognitivo.\n",
    "    c2: Parâmetro social.\n",
    "    w: Peso de inércia.\n",
    "\n",
    "    Retorna:\n",
    "    - Velocidade atualizada para a partícula.\n",
    "  '''\n",
    "  # inicializar vel atualizada\n",
    "  vel_updated = []\n",
    "  # loop em cada posição i da partícula\n",
    "  for i in range(len(pos)):\n",
    "      # Gera números aleatórios no intervalo [0, 1]\n",
    "      r1 = np.random.uniform(0,1)\n",
    "      r2 = np.random.uniform(0,1)\n",
    "\n",
    "      # Calcula os componentes cognitivo e social da atualização de velocidade\n",
    "      vel_cognitive = c1 * r1 * (pos_best[i] - pos[i])\n",
    "      vel_social = c2 * r2 * (global_best[i] - pos[i])\n",
    "\n",
    "      # Atualiza a velocidade i usando a fórmula do PSO\n",
    "      vel_updated.append(w * vel[i] + vel_cognitive + vel_social)\n",
    "\n",
    "  # Retorna a velocidade atualizada para a partícula\n",
    "  return np.array(vel_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir função de atualização da posição\n",
    "def update_position(pos, vel, bounds):\n",
    "  '''\n",
    "    Atualiza a posição da partícula a partir da nova velocidade.\n",
    "\n",
    "    Parâmetros:\n",
    "    pos: posição atual da partícula\n",
    "    vel: velocidade atualizada da partícula\n",
    "    bounds: limites do ambiente\n",
    "\n",
    "    Retorna:\n",
    "    - Velocidade atualizada para a partícula.\n",
    "  '''\n",
    "  pos_updated = []\n",
    "  for i in range(len(pos)):\n",
    "      pos_updated.append(np.clip(pos[i]+vel[i], a_min=bounds[0], a_max=bounds[1]))\n",
    "  return pos_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso(swarm_size, c1, c2, w, data, labels, beta, max_iters):\n",
    "  \"\"\"\n",
    "  Loop do PSO.\n",
    "\n",
    "  Parâmetros:\n",
    "  swarm_size: num de partículas.\n",
    "  c1: Parâmetro cognitivo.\n",
    "  c2: Parâmetro social.\n",
    "  w: Peso de inércia.\n",
    "  data: Dataset.\n",
    "  labels: labels das amostras.\n",
    "  beta: tamanho do subconjunto de features\n",
    "  max_iters: Número máximo de períodos.\n",
    "\n",
    "  Retorna:\n",
    "  Melhor subconjunto de features obtido pelo pso\n",
    "  \"\"\"\n",
    "  # inicializar os dados\n",
    "  X = data\n",
    "  y = labels\n",
    "  bounds = [0, 1] # já que posições são chaves aleatórias\n",
    "  # inicializar o enxame\n",
    "  pos_swarm, vel_swarm, pos_best_swarm = init_swarm(swarm_size,X)\n",
    "  # lista para armazenar evolução da fitness\n",
    "  fitness_over_time = []\n",
    "  bestind_over_time = []\n",
    "\n",
    "  # comece o loop\n",
    "  best_ind = pos_swarm[0] # initialize global best\n",
    "  for iter in range(max_iters):\n",
    "      print(\"iter: \" + str(iter))\n",
    "      # avaliar fitness das partículas do enxame\n",
    "      global_best_fitness = fitness_function(best_ind, beta, X, y) # fitness da melhor posição global\n",
    "      for j,ind in enumerate(pos_swarm):\n",
    "        score = fitness_function(ind, beta, X, y) # fitness da posição atual\n",
    "        score_known_best = fitness_function(pos_best_swarm[j], beta, X, y) # fitness da melhor posição conhecida\n",
    "        if score < score_known_best:\n",
    "          pos_best_swarm[j] = ind # se uma posição melhor for encontrada\n",
    "        if score < global_best_fitness:\n",
    "          best_ind = ind\n",
    "\n",
    "      # armazenar melhor fitness deste período\n",
    "      best_fitness_val = fitness_function(best_ind, beta, X, y)\n",
    "      print(-best_fitness_val)\n",
    "      fitness_over_time.append(-best_fitness_val)\n",
    "      bestind_over_time.append(best_ind)\n",
    "\n",
    "      # cycle through swarm and update velocities and position\n",
    "      for j in range(swarm_size):\n",
    "          vel_swarm[j] = update_velocity(pos_swarm[j], vel_swarm[j], pos_best_swarm[j], best_ind, w, c1, c2)\n",
    "          #pos_swarm[j] = update_position(pos_swarm[j], vel_swarm[j], [-1000,1000])\n",
    "          pos_swarm[j] = update_position(pos_swarm[j], vel_swarm[j], bounds)\n",
    "\n",
    "  return best_ind, fitness_over_time, bestind_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o conjunto de dados em treino e teste\n",
    "X_house = df_housing.drop('price',axis=1).copy()\n",
    "y_house = df_housing.price.copy()\n",
    "X_train_house, X_test_house, y_train_house, y_test_house = train_test_split(X_house, y_house, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(X_train_house.shape[1]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1540\\3226864843.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpca_house\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_house\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_train_house_PCA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_house\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_house\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test_house_PCA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_house\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_house\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             return_tuple = (\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mFortran\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mTo\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mit\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \"\"\"\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;34m\"PCA does not support sparse input. See \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m                 \u001b[1;34m\"TruncatedSVD for a possible alternative.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             )\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    484\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         )\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    600\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    920\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                 ) from complex_warning\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m         if (\n\u001b[0;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'yes'"
     ]
    }
   ],
   "source": [
    "pca_house = PCA(n_components=int(X_train_house.shape[1]/2))\n",
    "X_train_house_PCA = pca_house.fit_transform(X_train_house)\n",
    "X_test_house_PCA = pca_house.fit_transform(X_test_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussão dos resultados  \n",
    "O modelo com as melhores métricas foi tal, com R² de X e MSE de Y."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
