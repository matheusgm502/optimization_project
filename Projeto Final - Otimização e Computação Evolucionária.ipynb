{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Otimização e Computação Evolucionária\n",
    "\n",
    "\n",
    "## Alunos: Eduardo Ximenes, Matheus Gomes Maranhão, Vitor Peter\n",
    "\n",
    "O presente projeto foi realizado como atividade de conclusão da disciplina de Otimização e Computação Evolucionária. A atividade consiste no uso dos conhecimentos adquiridos ao longo das aulas, através da aplicação do Algoritmos Genético e Particle Swarm Optimization com o objetivo de realizar a clusterização de um dataset e regressão com seleção de features no outro dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score, jaccard_score, r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Churn Prediction  \n",
    "Com este dataset, será feita uma clusterização com o modelo KMeans usando um método fit ajustado por computação evolucionária. A ideia será comparar essa solução com o modelo padrão. A métrica utilizada foi o índice de silhueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('./data/churn_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  credit_score country  gender  age  tenure  balance  \\\n",
      "0     15634602           619  France  Female   42       2      0.0   \n",
      "\n",
      "   products_number  credit_card  active_member  estimated_salary  churn  \n",
      "0                1            1              1         101348.88      1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customer_id       10000 non-null  int64  \n",
      " 1   credit_score      10000 non-null  int64  \n",
      " 2   country           10000 non-null  object \n",
      " 3   gender            10000 non-null  object \n",
      " 4   age               10000 non-null  int64  \n",
      " 5   tenure            10000 non-null  int64  \n",
      " 6   balance           10000 non-null  float64\n",
      " 7   products_number   10000 non-null  int64  \n",
      " 8   credit_card       10000 non-null  int64  \n",
      " 9   active_member     10000 non-null  int64  \n",
      " 10  estimated_salary  10000 non-null  float64\n",
      " 11  churn             10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df_churn.head(1))\n",
    "df_churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score  gender  age  tenure    balance  products_number  credit_card  \\\n",
       "0           619       0   42       2       0.00                1            1   \n",
       "1           608       0   41       1   83807.86                1            0   \n",
       "2           502       0   42       8  159660.80                3            1   \n",
       "3           699       0   39       1       0.00                2            0   \n",
       "4           850       0   43       2  125510.82                1            1   \n",
       "\n",
       "   active_member  estimated_salary  Germany  Spain  \n",
       "0              1         101348.88        0      0  \n",
       "1              1         112542.58        0      1  \n",
       "2              0         113931.57        0      0  \n",
       "3              0          93826.63        0      0  \n",
       "4              1          79084.10        0      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df_churn.drop('churn',axis=1)\n",
    "y = df_churn['churn']\n",
    "\n",
    "X['gender'] = X['gender'].replace({'Male':1,'Female':0})\n",
    "\n",
    "dummies = pd.get_dummies(X['country'], drop_first=True)\n",
    "X.drop(['country','customer_id'],axis=1,inplace=True)\n",
    "X = pd.concat([X, dummies], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansEvol(KMeans):\n",
    "    def __init__(self, n_clusters=2, init='k-means++', precomputed_centroids=None, **kwargs):\n",
    "        super().__init__(n_clusters=n_clusters, init=init, **kwargs)\n",
    "        self.precomputed_centroids = precomputed_centroids # inicializar a variável que recebe os centróides otimizados pelo GA\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.cluster_centers_ = self.precomputed_centroids\n",
    "        self._n_threads = 1 # input para self.predict()\n",
    "        self.labels_ = self.predict(X)  # Prever partições de cada amostra\n",
    "        return self\n",
    "\n",
    "\n",
    "def init_pop(P,n_f,n_c, X):\n",
    "    \"\"\"\n",
    "    Inicialize P indivíduos da população. Cada indivíduo contém n_c\n",
    "    centróides.\n",
    "\n",
    "    Parâmetros:\n",
    "    P: Número de indivíduos na população\n",
    "    n_c: Número de centróides em cada grupo\n",
    "    n_f: Número de características no conjunto de dados\n",
    "    X: Conjunto de dados\n",
    "\n",
    "    Retorna:\n",
    "    população inicial com P indivíduos\n",
    "    \"\"\"\n",
    "    pop = []\n",
    "    # loop em todos os indivíduos\n",
    "    for _ in range(P):\n",
    "        # Inicializar indivíduo\n",
    "        centroids = []\n",
    "        # loop em cada centródide do indivíduo\n",
    "        for __ in range(n_c):\n",
    "          # loop em cada feature\n",
    "          centroid = []\n",
    "          for feature_index in range(n_f):\n",
    "              # Gerar a coordenada do centróide associada à feature\n",
    "              coordinate_f = np.random.uniform(np.min(X[:, feature_index]), np.max(X[:, feature_index]))\n",
    "              centroid.append(coordinate_f)\n",
    "          # adicionar centróide ao indivíduo\n",
    "          centroids.extend(centroid)\n",
    "        # adicionar indivíduo na pop\n",
    "        pop.append(np.array(centroids))\n",
    "\n",
    "    return pop\n",
    "\n",
    "def fitness_function(ind, n_clusters, X):\n",
    "\n",
    "    # Assumindo que o conjunto de centróides de um indivíduo é representado por:\n",
    "    #np.array([[x1_(1) x1_(2) x1_(3) ... x1_(n_f)] ... [x(n_c)_(1) x(n_c)_(2) x(n_c)_(3) ... x(n_c)_(n_f)] ])\n",
    "    # onde: n_f-> número de características, n_c-> número de clusters\n",
    "    # transformar em um array com dimensões (n_clusters x n_f)\n",
    "    ind_ready = np.reshape(ind, (n_clusters, len(X[0])))\n",
    "\n",
    "    # Criar instância do KMeansEvol\n",
    "    kmeans_ga = KMeansEvol(n_clusters=n_clusters, precomputed_centroids=ind_ready)\n",
    "    kmeans_ga.fit(X)\n",
    "\n",
    "    # Calcular a métrica silhouette como a fitness do indivíduo\n",
    "    labels = kmeans_ga.labels_\n",
    "    if all(x == labels[0] for x in labels): # se somente um cluster existir\n",
    "      silhouette_avg = -1\n",
    "    else:\n",
    "      silhouette_avg = silhouette_score(X, labels)\n",
    "\n",
    "\n",
    "    # Estamos maximizando a silhouette, então retorne o valor multiplicado por (-1)\n",
    "    return -silhouette_avg, kmeans_ga\n",
    "\n",
    "def select_individuals(population):\n",
    "    \"\"\"\n",
    "    Selecione dois indivíduos da população aleatoriamente para P seleções.\n",
    "\n",
    "    Parâmetros:\n",
    "    population: Lista ou array representando a população.\n",
    "\n",
    "    Retorna:\n",
    "    Lista de tuplas, cada uma contendo os índices de dois indivíduos selecionados aleatoriamente.\n",
    "    \"\"\"\n",
    "    population_size = len(population)\n",
    "    selections = []\n",
    "\n",
    "    for _ in range(population_size-1):\n",
    "        # Selecione dois indivíduos com reposição\n",
    "        selected_indices = np.random.choice(population_size, size=2, replace=True)\n",
    "        selections.append(tuple(selected_indices))\n",
    "\n",
    "    return selections\n",
    "\n",
    "def uniform_crossover(parent1, parent2, crossover_rate=0.5):\n",
    "    \"\"\"\n",
    "    Realize o cruzamento uniforme entre dois pais.\n",
    "\n",
    "    Parâmetros:\n",
    "    parent1: genes do primeiro pai.\n",
    "    parent2: genes do segundo pai.\n",
    "    crossover_rate: Probabilidade de selecionar um gene do parent1\n",
    "\n",
    "    Retorna:\n",
    "    genes da criança após o cruzamento uniforme.\n",
    "    \"\"\"\n",
    "\n",
    "    # Gerar uma lista aleatória booleana, onde o elemento da lista é igual a True, se p < crossover_rate\n",
    "    mask = np.random.rand(len(parent1)) < crossover_rate\n",
    "\n",
    "    # Realizar crossover\n",
    "    child = np.where(mask, parent1, parent2)\n",
    "\n",
    "    return child.tolist()\n",
    "\n",
    "def mutation(child, p_m=0.2, mutation_std_dev=0.1):\n",
    "    \"\"\"\n",
    "\n",
    "    Aplicar mutação aos genes de uma criança.\n",
    "\n",
    "    Parâmetros:\n",
    "    child: genes da criança.\n",
    "    p_m: Probabilidade de aplicar mutação a cada gene.\n",
    "    mutation_std_dev: Desvio padrão da distribuição normal para a mutação.\n",
    "\n",
    "    Retorna:\n",
    "    genes da criança após a mutação.\n",
    "    \"\"\"\n",
    "    mutated_child = np.copy(child)\n",
    "\n",
    "    # Faça o loop em cada gene e mute-o com probabilidade p_m\n",
    "    for i in range(len(child)):\n",
    "        if np.random.rand() < p_m:\n",
    "            # Aplique a mutação perturbando o gene com uma distribuição normal\n",
    "            mutated_child[i] += np.random.normal(loc=0, scale=mutation_std_dev)\n",
    "\n",
    "    return mutated_child.tolist()\n",
    "\n",
    "def genetic_algorithm(pop_size, p_crossover, p_mutation, data, n_clusters, max_generations):\n",
    "    \"\"\"\n",
    "    Loop do algoritmo genético.\n",
    "\n",
    "    Parâmetros:\n",
    "    pop_size: Tamanho da população.\n",
    "    p_crossover: Probabilidade de crossover.\n",
    "    p_mutation: Probabilidade de mutação.\n",
    "    X: Conjunto de dados.\n",
    "    n_clusters: Número de clusters.\n",
    "    n_features: Número de características.\n",
    "    max_generations: Número máximo de gerações.\n",
    "\n",
    "    Retorna:\n",
    "    Melhor conjunto de centróides obtido pelo algoritmo genético.\n",
    "    \"\"\"\n",
    "    # inicializar os dados\n",
    "    X = data\n",
    "    # inicializar pop\n",
    "    pop = init_pop(pop_size,11,n_clusters,X)\n",
    "    # lista para armazenar evolução da fitness\n",
    "    fitness_over_time = []\n",
    "    for generation in range(max_generations):\n",
    "        # avaliar fitness dos indivíduos da pop\n",
    "        #fitness_values = [fitness_function(ind, n_clusters, X) for ind in pop]\n",
    "        # selecionar melhor indivíduo com base na fitness\n",
    "        best_ind = min(pop, key=lambda ind: fitness_function(ind, n_clusters, X)[0])\n",
    "        # armazenar melhor fitness desta geração\n",
    "        best_fitness_val, best_kmeans_ga = fitness_function(best_ind, n_clusters, X)\n",
    "        fitness_over_time.append(-best_fitness_val)\n",
    "\n",
    "        # Selecionar pais para reprodução\n",
    "        selections = select_individuals(pop)\n",
    "\n",
    "        # Criar nova população com crossover e mutação\n",
    "        offspring = []\n",
    "        for parent1, parent2 in selections:\n",
    "            child = uniform_crossover(pop[parent1], pop[parent2], p_crossover)\n",
    "            child = mutation(child, p_mutation)\n",
    "            offspring.append(child)\n",
    "        offspring.append(best_ind)\n",
    "\n",
    "        # Atualizar população\n",
    "        pop = offspring\n",
    "\n",
    "    return best_ind, fitness_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   credit_score      10000 non-null  int64  \n",
      " 1   gender            10000 non-null  int64  \n",
      " 2   age               10000 non-null  int64  \n",
      " 3   tenure            10000 non-null  int64  \n",
      " 4   balance           10000 non-null  float64\n",
      " 5   products_number   10000 non-null  int64  \n",
      " 6   credit_card       10000 non-null  int64  \n",
      " 7   active_member     10000 non-null  int64  \n",
      " 8   estimated_salary  10000 non-null  float64\n",
      " 9   Germany           10000 non-null  uint8  \n",
      " 10  Spain             10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(7), uint8(2)\n",
      "memory usage: 722.8 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0) \n",
    "kmeans.fit(np.array(X))\n",
    "\n",
    "# The cluster centers (centroids)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# The labels of the clusters\n",
    "labels = kmeans.labels_\n",
    "\n",
    "labels = np.where(labels == 1, 3, np.where(labels == 0, 1, labels))\n",
    "labels =np.where(labels == 3, 0, labels)\n",
    "\n",
    "\n",
    "silhouette = silhouette_score(labels.reshape(-1, 1),np.array(y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\2817612987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m best_ind, fitness_over_time = genetic_algorithm(pop_size = 1,\n\u001b[0m\u001b[0;32m      2\u001b[0m                               \u001b[0mp_crossover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0mp_mutation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\3921536124.py\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[1;34m(pop_size, p_crossover, p_mutation, data, n_clusters, max_generations)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m#fitness_values = [fitness_function(ind, n_clusters, X) for ind in pop]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;31m# selecionar melhor indivíduo com base na fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mbest_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;31m# armazenar melhor fitness desta geração\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mbest_fitness_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_kmeans_ga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\3921536124.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(ind)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m#fitness_values = [fitness_function(ind, n_clusters, X) for ind in pop]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;31m# selecionar melhor indivíduo com base na fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mbest_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;31m# armazenar melhor fitness desta geração\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mbest_fitness_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_kmeans_ga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\3921536124.py\u001b[0m in \u001b[0;36mfitness_function\u001b[1;34m(ind, n_clusters, X)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0msilhouette_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[0msilhouette_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0m_silhouette_reduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_freqs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpairwise_distances_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m     \u001b[0mintra_clust_dists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minter_clust_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[0mintra_clust_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintra_clust_dists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1869\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2037\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2039\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    326\u001b[0m             )\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     if (\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_ind, fitness_over_time = genetic_algorithm(pop_size = 1,\n",
    "                              p_crossover = 0.5,\n",
    "                              p_mutation = 0.2,\n",
    "                              data = np.array(X),\n",
    "                              n_clusters = 3,\n",
    "                              max_generations = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\1412091381.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m best_ind, fitness_over_time = genetic_algorithm(pop_size = 50,\n\u001b[0m\u001b[0;32m      4\u001b[0m                               \u001b[0mp_crossover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[0mp_mutation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\1262845006.py\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[1;34m(pop_size, p_crossover, p_mutation, data, n_clusters, max_generations)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m#fitness_values = [fitness_function(ind, n_clusters, X) for ind in pop]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;31m# selecionar melhor indivíduo com base na fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mbest_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;31m# armazenar melhor fitness desta geração\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mbest_fitness_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_kmeans_ga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\1262845006.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(ind)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m#fitness_values = [fitness_function(ind, n_clusters, X) for ind in pop]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;31m# selecionar melhor indivíduo com base na fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mbest_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;31m# armazenar melhor fitness desta geração\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mbest_fitness_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_kmeans_ga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\1262845006.py\u001b[0m in \u001b[0;36mfitness_function\u001b[1;34m(ind, n_clusters, X)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0msilhouette_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[0msilhouette_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0m_silhouette_reduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_freqs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpairwise_distances_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m     \u001b[0mintra_clust_dists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minter_clust_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[0mintra_clust_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintra_clust_dists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1869\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2037\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2039\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    326\u001b[0m             )\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     if (\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "\n",
    "best_ind, fitness_over_time = genetic_algorithm(pop_size = 1,\n",
    "                              p_crossover = 0.5,\n",
    "                              p_mutation = 0.2,\n",
    "                              data = np.array(X),\n",
    "                              n_clusters = 3,\n",
    "                              max_generations = 100)\n",
    "\n",
    "best_fitness_ga, best_kmeans_ga = fitness_function(best_ind, n_clusters, X)\n",
    "score, kmeans = fitness_function(best_ind, n_clusters, X)\n",
    "labels = kmeans.labels_\n",
    "# Plotar a evolução da fitness ao longo das gerações\n",
    "plt.plot(range(1, len(fitness_over_time) + 1), fitness_over_time, marker='o')\n",
    "\n",
    "\n",
    "plt.title('Best Fitness Over Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Housing Prices  \n",
    "Com este dataset, será feita uma regressão com o modelo SVR usando features selecionadas por computação evolucionária. A ideia será comparar essa solução com o modelo utilizando todas as features, e com o modelo utilizando features escolhidas pelo PCA. As métricas utilizadas foram R² e MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000  7420         4          2        3      yes        no       no   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n",
      "None\n",
      "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000  7420         4          2        3      yes        no       no   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n"
     ]
    }
   ],
   "source": [
    "df_housing = pd.read_csv('./data/housing_price.csv')\n",
    "print(df_housing.head(1))\n",
    "print(df_housing.info())\n",
    "print(df_housing.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnished</th>\n",
       "      <th>semi-furnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000  7420         4          2        3         1          0   \n",
       "1  12250000  8960         4          4        4         1          0   \n",
       "2  12250000  9960         3          2        2         1          0   \n",
       "3  12215000  7500         4          2        2         1          0   \n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  furnished  \\\n",
       "0         0                0                1        2         1          1   \n",
       "1         0                0                1        3         0          1   \n",
       "2         1                0                0        2         1          0   \n",
       "3         1                0                1        3         1          1   \n",
       "4         1                0                1        2         0          1   \n",
       "\n",
       "   semi-furnished  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_house_bool = {'no':0, 'yes':1}\n",
    "booleans_house = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "for boolean_col in booleans_house:\n",
    "    df_housing[boolean_col] = df_housing[boolean_col].map(dict_house_bool)\n",
    "\n",
    "dict_house_furnish = {False:0, True:1}\n",
    "dummies_furnish = pd.get_dummies(df_housing.furnishingstatus)\n",
    "for furnish_col in dummies_furnish:\n",
    "    dummies_furnish[furnish_col] = dummies_furnish[furnish_col].map(dict_house_furnish)\n",
    "\n",
    "df_housing = df_housing.drop('furnishingstatus',axis=1)\n",
    "dummies_furnish = dummies_furnish.drop('unfurnished',axis=1)\n",
    "for col in dummies_furnish:\n",
    "    df_housing[col] = dummies_furnish[col]\n",
    "\n",
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computação evolucionária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para decodificar o indivíduo\n",
    "def decode_ind(ind, beta):\n",
    "    \"\"\"\n",
    "    Decodificar um indivíduo definindo 'beta' elementos com a maior\n",
    "    probabilidade como 1 e os demais como 0.\n",
    "\n",
    "    Parâmetros:\n",
    "    ind: indivíduo a ser decodificado.\n",
    "    beta: O número de elementos a serem definidos como 1.\n",
    "\n",
    "    Retorna:\n",
    "    ind: indivíduo a ser decodificado.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtenha os índices dos 'beta' maiores elementos\n",
    "    indices_of_highest = sorted(range(len(ind)), key=lambda i: ind[i], reverse=True)[:beta]\n",
    "    # []\n",
    "\n",
    "    # Innicialize o indivíduo decodificado\n",
    "    decoded_ind = [0] * len(ind)\n",
    "\n",
    "    # Inclua um total de 'beta' elementos iguais a 1\n",
    "    for index in indices_of_highest:\n",
    "        decoded_ind[index] = 1\n",
    "\n",
    "    return decoded_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a fitness no GA e no PSO\n",
    "def fitness_function(ind_encoded, beta, X, y):\n",
    "    # ind é um subconjunto de features: [0 0 1 0 0 1 ...]\n",
    "    ind = decode_ind(ind_encoded, beta)\n",
    "    # inicializar o alpha\n",
    "    alpha = np.inf\n",
    "    X_ind = []\n",
    "    for index in range(len(ind)):\n",
    "        if ind[index] == 1:\n",
    "            X_ind.append([X[item][index] for item in range(len(X))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.transpose(X_ind), y)\n",
    "    for i in range(10):\n",
    "        svm_fit = SVR()\n",
    "        svm_fit.fit(X_train, y_train)\n",
    "        prediction_fit = svm_fit.predict(X_test)\n",
    "        mse_fit = mean_squared_error(y_test, prediction_fit)\n",
    "        alpha = min(mse_fit, alpha)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que gera pop inicial\n",
    "def init_pop(P,X):\n",
    "    \"\"\"\n",
    "    Inicialize um conjunto de indivíduos, cada um contendo elementos entre 0 e 1.\n",
    "\n",
    "    Parâmetros:\n",
    "    X: dados de treinamento\n",
    "    P: número de indivíduos na população\n",
    "\n",
    "    Retorna:\n",
    "    pop: população inicial\n",
    "    \"\"\"\n",
    "    pop = []\n",
    "    m, n = X.shape\n",
    "    for _ in range(P):\n",
    "        ind = [np.random.uniform(0, 1) for __ in range(n)] # chaves aleatórias\n",
    "        pop.append(ind)\n",
    "\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_individuals(population, elite_size): # elitism is used\n",
    "    \"\"\"\n",
    "    Selecionar dois indivíduos aleatoriamente da população P vezes.\n",
    "    Como utilizamos elitismo, devemos reduzir o número de indivídos selecionados\n",
    "\n",
    "    Parâmetros:\n",
    "    population: Lista ou array representando a população.\n",
    "    elite_size: Tamanho da elite\n",
    "\n",
    "    Retorna:\n",
    "    Lista de tuplas, cada uma contendo os índices de dois indivíduos selecionados aleatoriamente.\n",
    "    \"\"\"\n",
    "    population_size = len(population)-math.ceil(elite_size)\n",
    "\n",
    "    selections = []\n",
    "    for _ in range(population_size):\n",
    "        # Selecione dois indivíduos aleatoriamente com reposição\n",
    "        selected_indices = np.random.choice(population_size, size=2, replace=True)\n",
    "        selections.append(tuple(selected_indices))\n",
    "\n",
    "    return selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_crossover(parent1, parent2, crossover_rate=0.5):\n",
    "    \"\"\"\n",
    "    Realizar crossover uniforme entre dois pais.\n",
    "\n",
    "    Parâmetros:\n",
    "\n",
    "    parent1: genes do primeiro pai.\n",
    "    parent2: genes do segundo pai.\n",
    "    crossover_rate: Probabilidade de selecionar um gene do primeiro pai.\n",
    "\n",
    "    Retorna:\n",
    "    genes do filho após o crossover uniforme.\n",
    "    \"\"\"\n",
    "\n",
    "    # Gerar uma lista aleatória booleana, onde o elemento da lista é igual a True, se p < crossover_rate\n",
    "    mask = np.random.rand(len(parent1)) < crossover_rate\n",
    "\n",
    "    # Realizar crossover\n",
    "    child = np.where(mask, parent1, parent2)\n",
    "\n",
    "    return child.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(child, p_m=0.2, mutation_std_dev=0.01):\n",
    "    \"\"\"\n",
    "\n",
    "    Aplicar mutação aos genes de uma criança.\n",
    "\n",
    "    Parâmetros:\n",
    "    child: genes da criança.\n",
    "    p_m: Probabilidade de aplicar mutação a cada gene.\n",
    "    mutation_std_dev: Desvio padrão da distribuição normal para a mutação.\n",
    "\n",
    "    Retorna:\n",
    "    genes da criança após a mutação.\n",
    "\n",
    "    * obs.: o std_dev foi reduzido e 0.1 para 0.01\n",
    "    \"\"\"\n",
    "    mutated_child = np.copy(child)\n",
    "\n",
    "    # Faça o loop em cada gene e mute-o com probabilidade p_m\n",
    "    for i in range(len(child)):\n",
    "        if np.random.rand() < p_m:\n",
    "            # Aplique a mutação perturbando o gene com uma distribuição normal\n",
    "            mutated_child[i] += np.random.normal(loc=0, scale=mutation_std_dev)\n",
    "\n",
    "    return mutated_child.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(pop_size, p_crossover, p_mutation, data, labels, beta, max_generations, elite_size):\n",
    "    \"\"\"\n",
    "    Loop do GA.\n",
    "\n",
    "    Parâmetros:\n",
    "    - pop_size: Population size.\n",
    "    - p_crossover: Crossover probability.\n",
    "    - p_mutation: Mutation probability.\n",
    "    - data: Dataset.\n",
    "    - labels: labels das amostras.\n",
    "    - beta: tamanho do subconjunto de features\n",
    "    - max_generations: Maximum number of generations.\n",
    "    - elite_size: tamanho da elite\n",
    "\n",
    "    Retorna:\n",
    "    - Melhor subconjunto de características obtido pelo GA\n",
    "    \"\"\"\n",
    "    # inicializar os dados\n",
    "    X = data\n",
    "    y = labels\n",
    "    # gerar pop inicial\n",
    "    pop = init_pop(pop_size,X)\n",
    "    # Listas para guardar melhores fitness e indivíduos\n",
    "    fitness_over_time = []\n",
    "    bestind_over_time = []\n",
    "    for generation in range(max_generations):\n",
    "        print(\"G: \" + str(generation))\n",
    "        # Avaliar a fitness de cada indivíduo\n",
    "        #fitness_values = [fitness_function(ind, beta, X, y) for ind in pop]\n",
    "        # Encontrar melhores indivíduos de acordo com a fitness\n",
    "        best_ind = sorted(pop, key=lambda ind: fitness_function(ind, beta, X, y))[:math.ceil(elite_size)]\n",
    "        # Guardar as melhores fitness e indivíduos\n",
    "        best_fitness_val = fitness_function(best_ind[0], beta, X, y)\n",
    "        print(best_fitness_val)\n",
    "        fitness_over_time.append(best_fitness_val)\n",
    "        bestind_over_time.append(best_ind[0])\n",
    "        #print(best_ind[0])\n",
    "\n",
    "        # Selecionar pais para reprodução\n",
    "        selections = select_individuals(pop, elite_size)\n",
    "\n",
    "        # Gerar nova pop através de crossover e mutação\n",
    "        offspring = []\n",
    "        for parent1, parent2 in selections:\n",
    "            child = uniform_crossover(pop[parent1], pop[parent2], p_crossover)\n",
    "            child = mutation(child, p_mutation)\n",
    "            offspring.append(child)\n",
    "\n",
    "        # Atualizar população\n",
    "        pop = offspring\n",
    "        pop.extend(best_ind)\n",
    "\n",
    "    return best_ind[0], fitness_over_time, bestind_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que gera enxame inicial\n",
    "def init_swarm(P,X):\n",
    "    \"\"\"\n",
    "    Inicialize um enxame com P partículas, cada uma contendo elementos entre 0 e 1.\n",
    "\n",
    "    Parâmetros:\n",
    "    X: dados de treinamento\n",
    "    P: número de indivíduos no enxame\n",
    "\n",
    "    Retorna:\n",
    "    pos = posição inicial das P partículas do enxame\n",
    "    vel = velocidade inicial das P partículas do enxame\n",
    "    pos_best = vetor de melhores posições conhecidas pela partícula\n",
    "    \"\"\"\n",
    "    pos = []\n",
    "    vel = []\n",
    "    pos_best = []\n",
    "    m, n = X.shape\n",
    "    for _ in range(P):\n",
    "        pos_ind = [np.random.uniform(0, 1) for __ in range(n)] # chaves aleatórias\n",
    "        pos.append(pos_ind)\n",
    "        pos_best.append(pos_ind)\n",
    "        vel.append(np.random.uniform(-1,1, size = n))\n",
    "\n",
    "    return pos, vel, pos_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atualizar velocidade da partícula\n",
    "def update_velocity(pos, vel, pos_best, global_best, w, c1, c2):\n",
    "  '''\n",
    "    Atualiza a velocidade da partícula usando a fórmula da Otimização por Enxame de Partículas (PSO).\n",
    "\n",
    "    Parâmetros:\n",
    "    pos: posição atual da partícula\n",
    "    vel: velocidade atual da partícula\n",
    "    pos_best: Melhor posição global entre todas as partículas.\n",
    "    c1: Parâmetro cognitivo.\n",
    "    c2: Parâmetro social.\n",
    "    w: Peso de inércia.\n",
    "\n",
    "    Retorna:\n",
    "    - Velocidade atualizada para a partícula.\n",
    "  '''\n",
    "  # inicializar vel atualizada\n",
    "  vel_updated = []\n",
    "  # loop em cada posição i da partícula\n",
    "  for i in range(len(pos)):\n",
    "      # Gera números aleatórios no intervalo [0, 1]\n",
    "      r1 = np.random.uniform(0,1)\n",
    "      r2 = np.random.uniform(0,1)\n",
    "\n",
    "      # Calcula os componentes cognitivo e social da atualização de velocidade\n",
    "      vel_cognitive = c1 * r1 * (pos_best[i] - pos[i])\n",
    "      vel_social = c2 * r2 * (global_best[i] - pos[i])\n",
    "\n",
    "      # Atualiza a velocidade i usando a fórmula do PSO\n",
    "      vel_updated.append(w * vel[i] + vel_cognitive + vel_social)\n",
    "\n",
    "  # Retorna a velocidade atualizada para a partícula\n",
    "  return np.array(vel_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir função de atualização da posição\n",
    "def update_position(pos, vel, bounds):\n",
    "  '''\n",
    "    Atualiza a posição da partícula a partir da nova velocidade.\n",
    "\n",
    "    Parâmetros:\n",
    "    pos: posição atual da partícula\n",
    "    vel: velocidade atualizada da partícula\n",
    "    bounds: limites do ambiente\n",
    "\n",
    "    Retorna:\n",
    "    - Velocidade atualizada para a partícula.\n",
    "  '''\n",
    "  pos_updated = []\n",
    "  for i in range(len(pos)):\n",
    "      pos_updated.append(np.clip(pos[i]+vel[i], a_min=bounds[0], a_max=bounds[1]))\n",
    "  return pos_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso(swarm_size, c1, c2, w, data, labels, beta, max_iters):\n",
    "  \"\"\"\n",
    "  Loop do PSO.\n",
    "\n",
    "  Parâmetros:\n",
    "  swarm_size: num de partículas.\n",
    "  c1: Parâmetro cognitivo.\n",
    "  c2: Parâmetro social.\n",
    "  w: Peso de inércia.\n",
    "  data: Dataset.\n",
    "  labels: labels das amostras.\n",
    "  beta: tamanho do subconjunto de features\n",
    "  max_iters: Número máximo de períodos.\n",
    "\n",
    "  Retorna:\n",
    "  Melhor subconjunto de features obtido pelo pso\n",
    "  \"\"\"\n",
    "  # inicializar os dados\n",
    "  X = data\n",
    "  y = labels\n",
    "  bounds = [0, 1] # já que posições são chaves aleatórias\n",
    "  # inicializar o enxame\n",
    "  pos_swarm, vel_swarm, pos_best_swarm = init_swarm(swarm_size,X)\n",
    "  # lista para armazenar evolução da fitness\n",
    "  fitness_over_time = []\n",
    "  bestind_over_time = []\n",
    "\n",
    "  # comece o loop\n",
    "  best_ind = pos_swarm[0] # initialize global best\n",
    "  for iter in range(max_iters):\n",
    "      print(\"iter: \" + str(iter))\n",
    "      # avaliar fitness das partículas do enxame\n",
    "      global_best_fitness = fitness_function(best_ind, beta, X, y) # fitness da melhor posição global\n",
    "      for j,ind in enumerate(pos_swarm):\n",
    "        score = fitness_function(ind, beta, X, y) # fitness da posição atual\n",
    "        score_known_best = fitness_function(pos_best_swarm[j], beta, X, y) # fitness da melhor posição conhecida\n",
    "        if score < score_known_best:\n",
    "          pos_best_swarm[j] = ind # se uma posição melhor for encontrada\n",
    "        if score < global_best_fitness:\n",
    "          best_ind = ind\n",
    "\n",
    "      # armazenar melhor fitness deste período\n",
    "      best_fitness_val = fitness_function(best_ind, beta, X, y)\n",
    "      print(best_fitness_val)\n",
    "      fitness_over_time.append(best_fitness_val)\n",
    "      bestind_over_time.append(best_ind)\n",
    "\n",
    "      # cycle through swarm and update velocities and position\n",
    "      for j in range(swarm_size):\n",
    "          vel_swarm[j] = update_velocity(pos_swarm[j], vel_swarm[j], pos_best_swarm[j], best_ind, w, c1, c2)\n",
    "          #pos_swarm[j] = update_position(pos_swarm[j], vel_swarm[j], [-1000,1000])\n",
    "          pos_swarm[j] = update_position(pos_swarm[j], vel_swarm[j], bounds)\n",
    "\n",
    "  return best_ind, fitness_over_time, bestind_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05154639 0.4        0.         0.33333333 1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.12852234 0.4        0.         0.         1.         0.\n",
      "  0.         0.         0.         0.66666667 1.         0.\n",
      "  0.        ]\n",
      " [0.33333333 0.4        0.33333333 0.66666667 1.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.        ]]\n",
      "[[0.32920962 0.2        0.         0.         1.         0.\n",
      "  0.         0.         1.         1.         0.         0.\n",
      "  1.        ]\n",
      " [0.20274914 0.4        0.33333333 0.33333333 1.         1.\n",
      "  0.         0.         1.         0.66666667 0.         1.\n",
      "  0.        ]\n",
      " [0.18213058 0.4        0.33333333 0.33333333 1.         0.\n",
      "  1.         0.         0.         0.33333333 0.         0.\n",
      "  0.        ]]\n",
      "533    2100000\n",
      "379    3633000\n",
      "127    5880000\n",
      "Name: price, dtype: int64\n",
      "225    4753000\n",
      "18     8890000\n",
      "48     7455000\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dividindo o conjunto de dados em X e y\n",
    "X_house = df_housing.drop('price',axis=1).copy()\n",
    "y_house = df_housing.price.copy()\n",
    "\n",
    "# Normalizando os valores do dataset\n",
    "scaler_house = MinMaxScaler()\n",
    "X_house = scaler_house.fit_transform(X_house)\n",
    "\n",
    "# Dividindo X e y em treino e teste\n",
    "X_train_house, X_test_house, y_train_house, y_test_house = train_test_split(X_house, y_house, test_size=0.25, random_state=101)\n",
    "\n",
    "print(X_train_house[:3])\n",
    "print(X_test_house[:3])\n",
    "print(y_train_house[:3])\n",
    "print(y_test_house[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0\n",
      "3432896881097.384\n",
      "G: 1\n",
      "2361237725939.5737\n",
      "G: 2\n",
      "4394127308827.7476\n",
      "G: 3\n",
      "4163004787776.841\n",
      "G: 4\n",
      "4006350707017.383\n",
      "G: 5\n",
      "2917899240934.9976\n",
      "G: 6\n",
      "3919454395578.5405\n",
      "G: 7\n",
      "4971726502388.051\n",
      "G: 8\n",
      "3385861493917.391\n",
      "G: 9\n",
      "3752918775633.08\n",
      "Melhor fitness: 4636021459759.423\n",
      "Colunas selecionadas: [1, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "# Selecionar um subconjunto de características de X_house com o GA\n",
    "best_fit_house_ga = np.inf\n",
    "beta_house = int(round(X_train_house.shape[1]*0.33))\n",
    "\n",
    "ind_house_ga, fitness_over_time_house_ga, bestind_over_time_house_ga = genetic_algorithm(pop_size=300, elite_size=50, \n",
    "                                                                                         p_crossover=0.5, p_mutation=0.2, \n",
    "                                                                                         data=X_train_house,\n",
    "                                                                                         labels=y_train_house,\n",
    "                                                                                         beta=beta_house, max_generations=10)\n",
    "best_fit_house_ga = fitness_function(ind_house_ga, beta_house, X_train_house, y_train_house)\n",
    "selected_cols_house_ga = [index for index, value in enumerate(decode_ind(ind_house_ga, beta_house)) if value == 1]\n",
    "\n",
    "print('Melhor fitness:', best_fit_house_ga)\n",
    "print('Colunas selecionadas:', selected_cols_house_ga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "3142092263506.011\n",
      "iter: 1\n",
      "2852300697093.9893\n",
      "iter: 2\n",
      "3943886263185.6265\n",
      "iter: 3\n",
      "4430253236468.2705\n",
      "iter: 4\n",
      "3435384401262.4663\n",
      "iter: 5\n",
      "2906704273855.4473\n",
      "iter: 6\n",
      "3440337760698.7812\n",
      "iter: 7\n",
      "4747134635115.048\n",
      "iter: 8\n",
      "4164538271646.643\n",
      "iter: 9\n"
     ]
    }
   ],
   "source": [
    "# Selecionar um subconjunto de características de X com o PSO\n",
    "best_fit_house_pso = np.inf\n",
    "\n",
    "ind_house_pso, fitness_over_time_house_pso, bestind_over_time_house_pso = pso(swarm_size=300, c1=2, c2=2, w=0.5, \n",
    "                                                                              data=X_house, labels=y_house,\n",
    "                                                                              beta=beta_house, max_iters=10)\n",
    "best_fit_house_pso = fitness_function(ind_house_pso, beta_house, X_train_house, y_train_house)\n",
    "selected_cols_house_pso = [index for index, value in enumerate(decode_ind(ind_house_pso, beta_house)) if value == 1]\n",
    "\n",
    "print('Melhor fitness:', best_fit_house_pso)\n",
    "print('Colunas selecionadas:', selected_cols_house_pso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_house = PCA(n_components=beta_house)\n",
    "X_train_house_PCA = pca_house.fit_transform(X_train_house)\n",
    "X_test_house_PCA = pca_house.fit_transform(X_test_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparação dos métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subconjunto de características\n",
    "X_train_house_ga = X_train_house.values[:, selected_cols_house_ga]\n",
    "X_test_house_ga = X_test_house.values[:, selected_cols_house_ga]\n",
    "X_train_house_pso = X_train_house.values[:, selected_cols_house_pso]\n",
    "X_test_house_pso = X_test_house.values[:, selected_cols_house_pso]\n",
    "\n",
    "# Todas as características\n",
    "# Não é necessário modificar X_train ou X_test, pois eles já contêm todas as características\n",
    "\n",
    "# Inicializar e treinar regressores\n",
    "svr_house_pca = SVR()\n",
    "svr_house_pca.fit(X_train_house_PCA, y_train_house)\n",
    "svr_house_ga = SVR()\n",
    "svr_house_ga.fit(X_train_house_ga, y_train_house)\n",
    "svr_house_pso = SVR()\n",
    "svr_house_pso.fit(X_train_house_pso, y_train_house)\n",
    "svr_house = SVR()\n",
    "svr_house.fit(X_train_house, y_train_house)\n",
    "\n",
    "# Avaliar e comparar o desempenho dos classificadores\n",
    "\n",
    "# Realizar previsões\n",
    "y_pred_house_pca = svr_house_pca.predict(X_test_house_PCA)\n",
    "y_pred_house_ga = svr_house_ga.predict(X_test_house_ga)\n",
    "y_pred_house_pso = svr_house_pso.predict(X_test_house_pso)\n",
    "y_pred_house = svr_house.predict(X_test_house)\n",
    "\n",
    "# Avaliar o R² score\n",
    "r2_house_pca = r2_score(y_test_house, y_pred_house_pca)\n",
    "r2_house_ga = r2_score(y_test_house, y_pred_house_ga)\n",
    "r2_house_pso = r2_score(y_test_house, y_pred_house_pso)\n",
    "r2_house = r2_score(y_test_house, y_pred_house)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"R² com subconjunto por PCA: {r2_house_pca:.2f}\")\n",
    "print(f\"R² com subconjunto por GA: {r2_house_ga:.2f}\")\n",
    "print(f\"R² com subconjunto por PSO: {r2_house_pso:.2f}\")\n",
    "print(f\"R² com todas as características: {r2_house:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que X seja seu conjunto de dados, subsets seja uma lista de selected_cols e y seja sua variável alvo\n",
    "\n",
    "# Avaliar o desempenho de referência\n",
    "baseline_r2_train_house = r2_score(y_train_house, svr_house.predict(X_train_house))\n",
    "baseline_r2_test_house = r2_score(y_test_house, svr_house.predict(X_test_house))\n",
    "\n",
    "# Avaliar o desempenho do PCA\n",
    "pca_r2_train_house = r2_score(y_train_house, svr_house_pca.predict(X_train_house_pca))\n",
    "pca_r2_test_house = r2_score(y_test_house, svr_house_pca.predict(X_test_house_pca))\n",
    "\n",
    "\n",
    "# Armazenar os resultados do GA\n",
    "train_r2_house_ga = []\n",
    "test_r2_house_ga = []\n",
    "\n",
    "# Iterar sobre subconjuntos de características do GA\n",
    "for ind in bestind_over_time_house_ga:\n",
    "    subset = [index for index, value in enumerate(decode_ind(ind, beta_house)) if value == 1]\n",
    "    # Extrair o subconjunto de características\n",
    "    X_subset_train_house_ga = X_train_house[:, subset]\n",
    "    X_subset_test_house_ga = X_test_house[:, subset]\n",
    "\n",
    "    # Inicializar e treinar o classificador\n",
    "    svr_subset_house_ga = SVR()\n",
    "    svr_subset_house_ga.fit(X_subset_train_house_ga, y_train_house)\n",
    "\n",
    "    # Avaliar o desempenho\n",
    "    r2_train_house_ga = r2_score(y_train_house, svr_subset_house_ga.predict(X_subset_train_house_ga))\n",
    "    r2_test_house_ga = r2_score(y_test_house, svr_subset_house_ga.predict(X_subset_test_house_ga))\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    train_r2_house_ga.append(r2_train_house_ga)\n",
    "    test_r2_house_ga.append(r2_test_house_ga)\n",
    "\n",
    "\n",
    "# Armazenar os resultados do PSO\n",
    "train_r2_house_pso = []\n",
    "test_r2_house_pso = []\n",
    "\n",
    "# Iterar sobre subconjuntos de características do PSO\n",
    "for ind in bestind_over_time_house_pso:\n",
    "    subset = [index for index, value in enumerate(decode_ind(ind, beta_house)) if value == 1]\n",
    "    # Extrair o subconjunto de características\n",
    "    X_subset_train_house_pso = X_train_house[:, subset]\n",
    "    X_subset_test_house_pso = X_test_house[:, subset]\n",
    "\n",
    "    # Inicializar e treinar o classificador\n",
    "    svr_subset_house_pso = SVR()\n",
    "    svr_subset_house_pso.fit(X_subset_train_house_pso, y_train_house)\n",
    "\n",
    "    # Avaliar o desempenho\n",
    "    r2_train_iris_pso = r2_score(y_train_house, svr_subset_house_pso.predict(X_subset_train_house_pso))\n",
    "    r2_test_iris_pso = r2_score(y_test_house, svr_subset_house_pso.predict(X_subset_test_house_pso))\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    train_r2_house_pso.append(r2_train_house_pso)\n",
    "    test_r2_house_pso.append(r2_test_house_pso)\n",
    "\n",
    "\n",
    "# Gráfico do treino\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_r2_house_ga, marker='o', color='blue', label='R² - GA')\n",
    "plt.plot(train_r2_house_pso, marker='o', color='green', label='R² - PSO')\n",
    "# Desenhe uma linha constante para o baseline (classificador que usa todas as características)\n",
    "plt.axhline(y=baseline_r2_train_house, color='red', linestyle='--', label='R² de Referência')\n",
    "plt.axhline(y=pca_r2_train_house, color='yellow', linestyle='--', label='R² PCA')\n",
    "plt.xlabel('Geração')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Evolução do R² no Treino com os melhores subconjuntos de características em cada Geração')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico do teste\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_r2_house_ga, marker='o', color='blue', label='R² - GA')\n",
    "plt.plot(test_r2_house_pso, marker='o', color='green', label='R² - PSO')\n",
    "# Desenhe uma linha constante para o baseline (classificador que usa todas as características)\n",
    "plt.axhline(y=baseline_r2_test_house, color='r', linestyle='--', label='R² de Referência')\n",
    "plt.axhline(y=pca_r2_test_house, color='yellow', linestyle='--', label='R² PCA')\n",
    "plt.xlabel('Geração')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.title('Evolução do R² no Teste com os melhores subconjuntos de características em cada Geração')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussão dos resultados  \n",
    "O modelo com as melhores métricas foi tal, com R² de X e MSE de Y."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
